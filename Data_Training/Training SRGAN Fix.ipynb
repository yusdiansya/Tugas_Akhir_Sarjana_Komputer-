{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded weights from pre-trained SRResNet.\n",
      "\n",
      "Epoch: [0][0/36]----Batch Time 0.479 (0.479)----Data Time 0.080 (0.080)----Cont. Loss 0.0403 (0.0403)----Adv. Loss 0.6628 (0.6628)----Disc. Loss 1.3912 (1.3912)\n",
      "Epoch: [0][1/36]----Batch Time 0.468 (0.473)----Data Time 0.088 (0.084)----Cont. Loss 0.3169 (0.1786)----Adv. Loss 2.4977 (1.5803)----Disc. Loss 2.5913 (1.9913)\n",
      "Epoch: [0][2/36]----Batch Time 0.452 (0.466)----Data Time 0.074 (0.080)----Cont. Loss 0.0663 (0.1412)----Adv. Loss 0.1663 (1.1090)----Disc. Loss 2.0993 (2.0273)\n",
      "Epoch: [0][3/36]----Batch Time 0.454 (0.463)----Data Time 0.074 (0.079)----Cont. Loss 0.0653 (0.1222)----Adv. Loss 0.2293 (0.8891)----Disc. Loss 1.8676 (1.9874)\n",
      "Epoch: [0][4/36]----Batch Time 0.452 (0.461)----Data Time 0.074 (0.078)----Cont. Loss 0.0683 (0.1114)----Adv. Loss 0.6390 (0.8390)----Disc. Loss 1.3948 (1.8689)\n",
      "Epoch: [0][5/36]----Batch Time 0.453 (0.459)----Data Time 0.075 (0.077)----Cont. Loss 0.0733 (0.1051)----Adv. Loss 1.0815 (0.8795)----Disc. Loss 1.5040 (1.8080)\n",
      "Epoch: [0][6/36]----Batch Time 0.454 (0.459)----Data Time 0.075 (0.077)----Cont. Loss 0.0747 (0.1007)----Adv. Loss 1.2310 (0.9297)----Disc. Loss 1.5805 (1.7755)\n",
      "Epoch: [0][7/36]----Batch Time 0.453 (0.458)----Data Time 0.075 (0.077)----Cont. Loss 0.0709 (0.0970)----Adv. Loss 1.1121 (0.9525)----Disc. Loss 1.5145 (1.7429)\n",
      "Epoch: [0][8/36]----Batch Time 0.458 (0.458)----Data Time 0.075 (0.076)----Cont. Loss 0.0734 (0.0944)----Adv. Loss 0.9441 (0.9515)----Disc. Loss 1.4388 (1.7091)\n",
      "Epoch: [0][9/36]----Batch Time 0.457 (0.458)----Data Time 0.076 (0.076)----Cont. Loss 0.0631 (0.0913)----Adv. Loss 0.7317 (0.9296)----Disc. Loss 1.3901 (1.6772)\n",
      "Epoch: [0][10/36]----Batch Time 0.460 (0.458)----Data Time 0.075 (0.076)----Cont. Loss 0.0541 (0.0879)----Adv. Loss 0.6061 (0.9002)----Disc. Loss 1.4007 (1.6521)\n",
      "Epoch: [0][11/36]----Batch Time 0.458 (0.458)----Data Time 0.075 (0.076)----Cont. Loss 0.0509 (0.0848)----Adv. Loss 0.5541 (0.8713)----Disc. Loss 1.4153 (1.6324)\n",
      "Epoch: [0][12/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.076)----Cont. Loss 0.0522 (0.0823)----Adv. Loss 0.5171 (0.8441)----Disc. Loss 1.4266 (1.6165)\n",
      "Epoch: [0][13/36]----Batch Time 0.454 (0.457)----Data Time 0.074 (0.076)----Cont. Loss 0.0613 (0.0808)----Adv. Loss 0.4972 (0.8193)----Disc. Loss 1.4536 (1.6049)\n",
      "Epoch: [0][14/36]----Batch Time 0.459 (0.457)----Data Time 0.075 (0.076)----Cont. Loss 0.0534 (0.0790)----Adv. Loss 0.5433 (0.8009)----Disc. Loss 1.4186 (1.5925)\n",
      "Epoch: [0][15/36]----Batch Time 0.453 (0.457)----Data Time 0.074 (0.076)----Cont. Loss 0.0509 (0.0772)----Adv. Loss 0.5724 (0.7866)----Disc. Loss 1.4086 (1.5810)\n",
      "Epoch: [0][16/36]----Batch Time 0.456 (0.457)----Data Time 0.075 (0.076)----Cont. Loss 0.0495 (0.0756)----Adv. Loss 0.6253 (0.7771)----Disc. Loss 1.3984 (1.5702)\n",
      "Epoch: [0][17/36]----Batch Time 0.478 (0.458)----Data Time 0.077 (0.076)----Cont. Loss 0.0499 (0.0742)----Adv. Loss 0.6949 (0.7726)----Disc. Loss 1.3926 (1.5604)\n",
      "Epoch: [0][18/36]----Batch Time 0.489 (0.460)----Data Time 0.079 (0.076)----Cont. Loss 0.0509 (0.0729)----Adv. Loss 0.7733 (0.7726)----Disc. Loss 1.3945 (1.5516)\n",
      "Epoch: [0][19/36]----Batch Time 0.478 (0.461)----Data Time 0.075 (0.076)----Cont. Loss 0.0534 (0.0719)----Adv. Loss 0.8010 (0.7740)----Disc. Loss 1.4010 (1.5441)\n",
      "Epoch: [0][20/36]----Batch Time 0.456 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0433 (0.0706)----Adv. Loss 0.8207 (0.7762)----Disc. Loss 1.4034 (1.5374)\n",
      "Epoch: [0][21/36]----Batch Time 0.462 (0.461)----Data Time 0.079 (0.076)----Cont. Loss 0.0468 (0.0695)----Adv. Loss 0.8346 (0.7789)----Disc. Loss 1.4060 (1.5314)\n",
      "Epoch: [0][22/36]----Batch Time 0.459 (0.460)----Data Time 0.076 (0.076)----Cont. Loss 0.0478 (0.0686)----Adv. Loss 0.8232 (0.7808)----Disc. Loss 1.4058 (1.5260)\n",
      "Epoch: [0][23/36]----Batch Time 0.465 (0.461)----Data Time 0.077 (0.076)----Cont. Loss 0.0578 (0.0681)----Adv. Loss 0.7869 (0.7811)----Disc. Loss 1.3962 (1.5206)\n",
      "Epoch: [0][24/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0537 (0.0675)----Adv. Loss 0.7535 (0.7800)----Disc. Loss 1.3916 (1.5154)\n",
      "Epoch: [0][25/36]----Batch Time 0.461 (0.461)----Data Time 0.075 (0.076)----Cont. Loss 0.0421 (0.0666)----Adv. Loss 0.7186 (0.7776)----Disc. Loss 1.3887 (1.5105)\n",
      "Epoch: [0][26/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0453 (0.0658)----Adv. Loss 0.6829 (0.7741)----Disc. Loss 1.3871 (1.5060)\n",
      "Epoch: [0][27/36]----Batch Time 0.462 (0.460)----Data Time 0.076 (0.076)----Cont. Loss 0.0451 (0.0650)----Adv. Loss 0.6545 (0.7698)----Disc. Loss 1.3895 (1.5018)\n",
      "Epoch: [0][28/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0491 (0.0645)----Adv. Loss 0.6344 (0.7652)----Disc. Loss 1.3909 (1.4980)\n",
      "Epoch: [0][29/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0480 (0.0639)----Adv. Loss 0.6202 (0.7603)----Disc. Loss 1.3929 (1.4945)\n",
      "Epoch: [0][30/36]----Batch Time 0.458 (0.460)----Data Time 0.076 (0.076)----Cont. Loss 0.0498 (0.0635)----Adv. Loss 0.6204 (0.7558)----Disc. Loss 1.3913 (1.4911)\n",
      "Epoch: [0][31/36]----Batch Time 0.463 (0.460)----Data Time 0.077 (0.076)----Cont. Loss 0.0368 (0.0626)----Adv. Loss 0.6272 (0.7518)----Disc. Loss 1.3909 (1.4880)\n",
      "Epoch: [0][32/36]----Batch Time 0.458 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0475 (0.0622)----Adv. Loss 0.6496 (0.7487)----Disc. Loss 1.3874 (1.4850)\n",
      "Epoch: [0][33/36]----Batch Time 0.466 (0.460)----Data Time 0.075 (0.076)----Cont. Loss 0.0485 (0.0618)----Adv. Loss 0.6685 (0.7463)----Disc. Loss 1.3877 (1.4821)\n",
      "Epoch: [0][34/36]----Batch Time 0.471 (0.461)----Data Time 0.075 (0.076)----Cont. Loss 0.0467 (0.0614)----Adv. Loss 0.6883 (0.7447)----Disc. Loss 1.3853 (1.4793)\n",
      "Epoch: [0][35/36]----Batch Time 1.578 (0.492)----Data Time 0.055 (0.075)----Cont. Loss 0.0394 (0.0609)----Adv. Loss 0.6951 (0.7437)----Disc. Loss 1.3857 (1.4775)\n",
      "Epoch: [1][0/36]----Batch Time 0.488 (0.488)----Data Time 0.074 (0.074)----Cont. Loss 0.0442 (0.0442)----Adv. Loss 0.7245 (0.7245)----Disc. Loss 1.3845 (1.3845)\n",
      "Epoch: [1][1/36]----Batch Time 0.460 (0.474)----Data Time 0.077 (0.075)----Cont. Loss 0.0460 (0.0451)----Adv. Loss 0.7329 (0.7287)----Disc. Loss 1.3876 (1.3861)\n",
      "Epoch: [1][2/36]----Batch Time 0.456 (0.468)----Data Time 0.075 (0.075)----Cont. Loss 0.0469 (0.0457)----Adv. Loss 0.7332 (0.7302)----Disc. Loss 1.3857 (1.3860)\n",
      "Epoch: [1][3/36]----Batch Time 0.458 (0.465)----Data Time 0.077 (0.076)----Cont. Loss 0.0532 (0.0476)----Adv. Loss 0.7442 (0.7337)----Disc. Loss 1.3876 (1.3864)\n",
      "Epoch: [1][4/36]----Batch Time 0.458 (0.464)----Data Time 0.075 (0.075)----Cont. Loss 0.0390 (0.0459)----Adv. Loss 0.7272 (0.7324)----Disc. Loss 1.3851 (1.3861)\n",
      "Epoch: [1][5/36]----Batch Time 0.456 (0.462)----Data Time 0.075 (0.075)----Cont. Loss 0.0423 (0.0453)----Adv. Loss 0.7299 (0.7320)----Disc. Loss 1.3847 (1.3859)\n",
      "Epoch: [1][6/36]----Batch Time 0.453 (0.461)----Data Time 0.073 (0.075)----Cont. Loss 0.0406 (0.0446)----Adv. Loss 0.7084 (0.7286)----Disc. Loss 1.3846 (1.3857)\n",
      "Epoch: [1][7/36]----Batch Time 0.455 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0444 (0.0446)----Adv. Loss 0.7097 (0.7262)----Disc. Loss 1.3838 (1.3855)\n",
      "Epoch: [1][8/36]----Batch Time 0.459 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0380 (0.0439)----Adv. Loss 0.6815 (0.7213)----Disc. Loss 1.3836 (1.3853)\n",
      "Epoch: [1][9/36]----Batch Time 0.456 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0514 (0.0446)----Adv. Loss 0.6835 (0.7175)----Disc. Loss 1.3831 (1.3850)\n",
      "Epoch: [1][10/36]----Batch Time 0.454 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0379 (0.0440)----Adv. Loss 0.6814 (0.7142)----Disc. Loss 1.3830 (1.3849)\n",
      "Epoch: [1][11/36]----Batch Time 0.454 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0440 (0.0440)----Adv. Loss 0.6718 (0.7107)----Disc. Loss 1.3826 (1.3847)\n",
      "Epoch: [1][12/36]----Batch Time 0.456 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0377 (0.0435)----Adv. Loss 0.6689 (0.7075)----Disc. Loss 1.3835 (1.3846)\n",
      "Epoch: [1][13/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.075)----Cont. Loss 0.0417 (0.0434)----Adv. Loss 0.6811 (0.7056)----Disc. Loss 1.3831 (1.3845)\n",
      "Epoch: [1][14/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.075)----Cont. Loss 0.0458 (0.0435)----Adv. Loss 0.6801 (0.7039)----Disc. Loss 1.3804 (1.3842)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][15/36]----Batch Time 0.454 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0414 (0.0434)----Adv. Loss 0.6907 (0.7030)----Disc. Loss 1.3807 (1.3840)\n",
      "Epoch: [1][16/36]----Batch Time 0.460 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0484 (0.0437)----Adv. Loss 0.6885 (0.7022)----Disc. Loss 1.3823 (1.3839)\n",
      "Epoch: [1][17/36]----Batch Time 0.455 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0407 (0.0435)----Adv. Loss 0.7078 (0.7025)----Disc. Loss 1.3812 (1.3837)\n",
      "Epoch: [1][18/36]----Batch Time 0.456 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0525 (0.0440)----Adv. Loss 0.7130 (0.7031)----Disc. Loss 1.3795 (1.3835)\n",
      "Epoch: [1][19/36]----Batch Time 0.454 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0347 (0.0435)----Adv. Loss 0.7156 (0.7037)----Disc. Loss 1.3789 (1.3833)\n",
      "Epoch: [1][20/36]----Batch Time 0.457 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0377 (0.0433)----Adv. Loss 0.7277 (0.7048)----Disc. Loss 1.3787 (1.3831)\n",
      "Epoch: [1][21/36]----Batch Time 0.455 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0361 (0.0429)----Adv. Loss 0.7235 (0.7057)----Disc. Loss 1.3763 (1.3828)\n",
      "Epoch: [1][22/36]----Batch Time 0.454 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0493 (0.0432)----Adv. Loss 0.7085 (0.7058)----Disc. Loss 1.3750 (1.3824)\n",
      "Epoch: [1][23/36]----Batch Time 0.454 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0390 (0.0430)----Adv. Loss 0.6986 (0.7055)----Disc. Loss 1.3753 (1.3821)\n",
      "Epoch: [1][24/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0370 (0.0428)----Adv. Loss 0.6836 (0.7046)----Disc. Loss 1.3735 (1.3818)\n",
      "Epoch: [1][25/36]----Batch Time 0.460 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0356 (0.0425)----Adv. Loss 0.6920 (0.7041)----Disc. Loss 1.3726 (1.3814)\n",
      "Epoch: [1][26/36]----Batch Time 0.458 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0387 (0.0424)----Adv. Loss 0.6898 (0.7036)----Disc. Loss 1.3710 (1.3810)\n",
      "Epoch: [1][27/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0381 (0.0422)----Adv. Loss 0.6993 (0.7035)----Disc. Loss 1.3684 (1.3806)\n",
      "Epoch: [1][28/36]----Batch Time 0.456 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0382 (0.0421)----Adv. Loss 0.6963 (0.7032)----Disc. Loss 1.3682 (1.3802)\n",
      "Epoch: [1][29/36]----Batch Time 0.457 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0423 (0.0421)----Adv. Loss 0.6833 (0.7026)----Disc. Loss 1.3645 (1.3796)\n",
      "Epoch: [1][30/36]----Batch Time 0.454 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0338 (0.0418)----Adv. Loss 0.7213 (0.7032)----Disc. Loss 1.3594 (1.3790)\n",
      "Epoch: [1][31/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0411 (0.0418)----Adv. Loss 0.7167 (0.7036)----Disc. Loss 1.3556 (1.3783)\n",
      "Epoch: [1][32/36]----Batch Time 0.460 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0334 (0.0416)----Adv. Loss 0.7190 (0.7040)----Disc. Loss 1.3525 (1.3775)\n",
      "Epoch: [1][33/36]----Batch Time 0.455 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0366 (0.0414)----Adv. Loss 0.7434 (0.7052)----Disc. Loss 1.3469 (1.3766)\n",
      "Epoch: [1][34/36]----Batch Time 0.456 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0320 (0.0411)----Adv. Loss 0.7099 (0.7053)----Disc. Loss 1.3426 (1.3756)\n",
      "Epoch: [1][35/36]----Batch Time 0.341 (0.454)----Data Time 0.054 (0.074)----Cont. Loss 0.0410 (0.0411)----Adv. Loss 0.7672 (0.7066)----Disc. Loss 1.3305 (1.3747)\n",
      "Epoch: [2][0/36]----Batch Time 0.464 (0.464)----Data Time 0.075 (0.075)----Cont. Loss 0.0345 (0.0345)----Adv. Loss 0.7103 (0.7103)----Disc. Loss 1.3198 (1.3198)\n",
      "Epoch: [2][1/36]----Batch Time 0.461 (0.462)----Data Time 0.074 (0.074)----Cont. Loss 0.0419 (0.0382)----Adv. Loss 0.7887 (0.7495)----Disc. Loss 1.3043 (1.3120)\n",
      "Epoch: [2][2/36]----Batch Time 0.458 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0435 (0.0400)----Adv. Loss 0.6744 (0.7244)----Disc. Loss 1.2910 (1.3050)\n",
      "Epoch: [2][3/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.074)----Cont. Loss 0.0391 (0.0398)----Adv. Loss 0.7813 (0.7387)----Disc. Loss 1.2507 (1.2914)\n",
      "Epoch: [2][4/36]----Batch Time 0.455 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0354 (0.0389)----Adv. Loss 1.0997 (0.8109)----Disc. Loss 1.2802 (1.2892)\n",
      "Epoch: [2][5/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0445 (0.0398)----Adv. Loss 0.5990 (0.7756)----Disc. Loss 1.2517 (1.2829)\n",
      "Epoch: [2][6/36]----Batch Time 0.455 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0391 (0.0397)----Adv. Loss 0.8208 (0.7820)----Disc. Loss 1.1312 (1.2613)\n",
      "Epoch: [2][7/36]----Batch Time 0.454 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0423 (0.0400)----Adv. Loss 1.2301 (0.8380)----Disc. Loss 1.1118 (1.2426)\n",
      "Epoch: [2][8/36]----Batch Time 0.457 (0.457)----Data Time 0.076 (0.074)----Cont. Loss 0.0396 (0.0400)----Adv. Loss 0.6020 (0.8118)----Disc. Loss 1.2107 (1.2390)\n",
      "Epoch: [2][9/36]----Batch Time 0.455 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0368 (0.0397)----Adv. Loss 1.2632 (0.8569)----Disc. Loss 1.1536 (1.2305)\n",
      "Epoch: [2][10/36]----Batch Time 0.458 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0360 (0.0393)----Adv. Loss 0.6142 (0.8349)----Disc. Loss 1.1551 (1.2236)\n",
      "Epoch: [2][11/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0347 (0.0390)----Adv. Loss 2.3350 (0.9599)----Disc. Loss 1.4968 (1.2464)\n",
      "Epoch: [2][12/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0380 (0.0389)----Adv. Loss 0.5574 (0.9289)----Disc. Loss 1.2249 (1.2447)\n",
      "Epoch: [2][13/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0410 (0.0390)----Adv. Loss 0.7566 (0.9166)----Disc. Loss 1.0631 (1.2318)\n",
      "Epoch: [2][14/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0348 (0.0387)----Adv. Loss 1.6685 (0.9667)----Disc. Loss 1.1231 (1.2245)\n",
      "Epoch: [2][15/36]----Batch Time 0.454 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0357 (0.0386)----Adv. Loss 0.8859 (0.9617)----Disc. Loss 0.9605 (1.2080)\n",
      "Epoch: [2][16/36]----Batch Time 0.454 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0429 (0.0388)----Adv. Loss 0.9932 (0.9635)----Disc. Loss 0.9526 (1.1930)\n",
      "Epoch: [2][17/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0367 (0.0387)----Adv. Loss 1.2151 (0.9775)----Disc. Loss 0.8669 (1.1749)\n",
      "Epoch: [2][18/36]----Batch Time 0.454 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0353 (0.0385)----Adv. Loss 0.6739 (0.9615)----Disc. Loss 0.9973 (1.1655)\n",
      "Epoch: [2][19/36]----Batch Time 0.453 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0381 (0.0385)----Adv. Loss 2.0404 (1.0155)----Disc. Loss 1.5246 (1.1835)\n",
      "Epoch: [2][20/36]----Batch Time 0.456 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0430 (0.0387)----Adv. Loss 0.4005 (0.9862)----Disc. Loss 2.0789 (1.2261)\n",
      "Epoch: [2][21/36]----Batch Time 0.457 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0323 (0.0384)----Adv. Loss 0.5720 (0.9674)----Disc. Loss 1.6097 (1.2436)\n",
      "Epoch: [2][22/36]----Batch Time 0.455 (0.456)----Data Time 0.074 (0.074)----Cont. Loss 0.0438 (0.0387)----Adv. Loss 1.3368 (0.9834)----Disc. Loss 1.5002 (1.2547)\n",
      "Epoch: [2][23/36]----Batch Time 0.458 (0.456)----Data Time 0.076 (0.074)----Cont. Loss 0.0364 (0.0386)----Adv. Loss 1.5235 (1.0059)----Disc. Loss 1.5971 (1.2690)\n",
      "Epoch: [2][24/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0352 (0.0384)----Adv. Loss 0.9303 (1.0029)----Disc. Loss 1.3798 (1.2734)\n",
      "Epoch: [2][25/36]----Batch Time 0.458 (0.456)----Data Time 0.076 (0.074)----Cont. Loss 0.0385 (0.0384)----Adv. Loss 0.4076 (0.9800)----Disc. Loss 1.5361 (1.2835)\n",
      "Epoch: [2][26/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0351 (0.0383)----Adv. Loss 0.4135 (0.9590)----Disc. Loss 1.5235 (1.2924)\n",
      "Epoch: [2][27/36]----Batch Time 0.460 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0434 (0.0385)----Adv. Loss 0.4818 (0.9420)----Disc. Loss 1.4236 (1.2971)\n",
      "Epoch: [2][28/36]----Batch Time 0.456 (0.456)----Data Time 0.076 (0.074)----Cont. Loss 0.0345 (0.0384)----Adv. Loss 0.5802 (0.9295)----Disc. Loss 1.3731 (1.2997)\n",
      "Epoch: [2][29/36]----Batch Time 0.457 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0369 (0.0383)----Adv. Loss 0.9177 (0.9291)----Disc. Loss 1.3311 (1.3008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][30/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0355 (0.0382)----Adv. Loss 1.0959 (0.9345)----Disc. Loss 1.3765 (1.3032)\n",
      "Epoch: [2][31/36]----Batch Time 0.455 (0.456)----Data Time 0.073 (0.074)----Cont. Loss 0.0334 (0.0381)----Adv. Loss 1.1011 (0.9397)----Disc. Loss 1.3603 (1.3050)\n",
      "Epoch: [2][32/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0436 (0.0382)----Adv. Loss 1.0990 (0.9445)----Disc. Loss 1.3458 (1.3062)\n",
      "Epoch: [2][33/36]----Batch Time 0.456 (0.456)----Data Time 0.075 (0.074)----Cont. Loss 0.0404 (0.0383)----Adv. Loss 1.0203 (0.9468)----Disc. Loss 1.3041 (1.3062)\n",
      "Epoch: [2][34/36]----Batch Time 0.458 (0.456)----Data Time 0.076 (0.074)----Cont. Loss 0.0415 (0.0384)----Adv. Loss 0.7964 (0.9425)----Disc. Loss 1.2394 (1.3042)\n",
      "Epoch: [2][35/36]----Batch Time 0.339 (0.453)----Data Time 0.053 (0.074)----Cont. Loss 0.0365 (0.0383)----Adv. Loss 0.6563 (0.9367)----Disc. Loss 1.2573 (1.3033)\n",
      "Epoch: [3][0/36]----Batch Time 0.475 (0.475)----Data Time 0.074 (0.074)----Cont. Loss 0.0396 (0.0396)----Adv. Loss 0.6813 (0.6813)----Disc. Loss 1.2228 (1.2228)\n",
      "Epoch: [3][1/36]----Batch Time 0.458 (0.466)----Data Time 0.074 (0.074)----Cont. Loss 0.0364 (0.0380)----Adv. Loss 0.6497 (0.6655)----Disc. Loss 1.1887 (1.2057)\n",
      "Epoch: [3][2/36]----Batch Time 0.456 (0.463)----Data Time 0.074 (0.074)----Cont. Loss 0.0349 (0.0370)----Adv. Loss 0.7556 (0.6956)----Disc. Loss 1.0983 (1.1699)\n",
      "Epoch: [3][3/36]----Batch Time 0.455 (0.461)----Data Time 0.075 (0.074)----Cont. Loss 0.0420 (0.0382)----Adv. Loss 0.9239 (0.7526)----Disc. Loss 1.0257 (1.1339)\n",
      "Epoch: [3][4/36]----Batch Time 0.458 (0.460)----Data Time 0.076 (0.074)----Cont. Loss 0.0378 (0.0381)----Adv. Loss 1.2837 (0.8589)----Disc. Loss 1.0553 (1.1182)\n",
      "Epoch: [3][5/36]----Batch Time 0.458 (0.460)----Data Time 0.073 (0.074)----Cont. Loss 0.0373 (0.0380)----Adv. Loss 1.1790 (0.9122)----Disc. Loss 0.8779 (1.0781)\n",
      "Epoch: [3][6/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0354 (0.0376)----Adv. Loss 1.0891 (0.9375)----Disc. Loss 0.8166 (1.0407)\n",
      "Epoch: [3][7/36]----Batch Time 0.455 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0373 (0.0376)----Adv. Loss 1.5378 (1.0125)----Disc. Loss 0.6699 (0.9944)\n",
      "Epoch: [3][8/36]----Batch Time 0.456 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0326 (0.0370)----Adv. Loss 1.6610 (1.0846)----Disc. Loss 0.5388 (0.9438)\n",
      "Epoch: [3][9/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0361 (0.0369)----Adv. Loss 1.8218 (1.1583)----Disc. Loss 0.4686 (0.8963)\n",
      "Epoch: [3][10/36]----Batch Time 0.461 (0.458)----Data Time 0.076 (0.074)----Cont. Loss 0.0400 (0.0372)----Adv. Loss 2.6118 (1.2904)----Disc. Loss 0.2988 (0.8419)\n",
      "Epoch: [3][11/36]----Batch Time 0.459 (0.458)----Data Time 0.077 (0.074)----Cont. Loss 0.0449 (0.0378)----Adv. Loss 2.2437 (1.3699)----Disc. Loss 0.3493 (0.8009)\n",
      "Epoch: [3][12/36]----Batch Time 0.461 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0394 (0.0380)----Adv. Loss 2.4764 (1.4550)----Disc. Loss 0.4359 (0.7728)\n",
      "Epoch: [3][13/36]----Batch Time 0.456 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0462 (0.0386)----Adv. Loss 5.9253 (1.7743)----Disc. Loss 1.3653 (0.8151)\n",
      "Epoch: [3][14/36]----Batch Time 0.455 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0357 (0.0384)----Adv. Loss 0.0246 (1.6577)----Disc. Loss 7.8314 (1.2829)\n",
      "Epoch: [3][15/36]----Batch Time 0.456 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0364 (0.0382)----Adv. Loss 0.0808 (1.5591)----Disc. Loss 3.8675 (1.4444)\n",
      "Epoch: [3][16/36]----Batch Time 0.455 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0434 (0.0386)----Adv. Loss 0.6700 (1.5068)----Disc. Loss 1.9923 (1.4767)\n",
      "Epoch: [3][17/36]----Batch Time 0.457 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0317 (0.0382)----Adv. Loss 1.8857 (1.5278)----Disc. Loss 2.7723 (1.5486)\n",
      "Epoch: [3][18/36]----Batch Time 0.455 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0414 (0.0383)----Adv. Loss 2.0309 (1.5543)----Disc. Loss 2.7399 (1.6113)\n",
      "Epoch: [3][19/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0373 (0.0383)----Adv. Loss 1.7093 (1.5621)----Disc. Loss 2.2936 (1.6454)\n",
      "Epoch: [3][20/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0394 (0.0383)----Adv. Loss 1.2571 (1.5476)----Disc. Loss 1.7962 (1.6526)\n",
      "Epoch: [3][21/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0364 (0.0383)----Adv. Loss 0.8780 (1.5171)----Disc. Loss 1.5486 (1.6479)\n",
      "Epoch: [3][22/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0394 (0.0383)----Adv. Loss 0.6554 (1.4797)----Disc. Loss 1.4632 (1.6399)\n",
      "Epoch: [3][23/36]----Batch Time 0.458 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0354 (0.0382)----Adv. Loss 0.4467 (1.4366)----Disc. Loss 1.5463 (1.6360)\n",
      "Epoch: [3][24/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0380 (0.0382)----Adv. Loss 0.3556 (1.3934)----Disc. Loss 1.6264 (1.6356)\n",
      "Epoch: [3][25/36]----Batch Time 0.455 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0356 (0.0381)----Adv. Loss 0.3687 (1.3540)----Disc. Loss 1.6142 (1.6348)\n",
      "Epoch: [3][26/36]----Batch Time 0.457 (0.457)----Data Time 0.076 (0.074)----Cont. Loss 0.0401 (0.0382)----Adv. Loss 0.4090 (1.3190)----Disc. Loss 1.5550 (1.6318)\n",
      "Epoch: [3][27/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0387 (0.0382)----Adv. Loss 0.5087 (1.2900)----Disc. Loss 1.4543 (1.6255)\n",
      "Epoch: [3][28/36]----Batch Time 0.459 (0.457)----Data Time 0.077 (0.075)----Cont. Loss 0.0319 (0.0380)----Adv. Loss 0.6123 (1.2667)----Disc. Loss 1.4237 (1.6185)\n",
      "Epoch: [3][29/36]----Batch Time 0.456 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0352 (0.0379)----Adv. Loss 0.7814 (1.2505)----Disc. Loss 1.4127 (1.6116)\n",
      "Epoch: [3][30/36]----Batch Time 0.461 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0376 (0.0379)----Adv. Loss 0.9573 (1.2410)----Disc. Loss 1.4538 (1.6066)\n",
      "Epoch: [3][31/36]----Batch Time 0.458 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0386 (0.0379)----Adv. Loss 1.0105 (1.2338)----Disc. Loss 1.4662 (1.6022)\n",
      "Epoch: [3][32/36]----Batch Time 0.459 (0.457)----Data Time 0.073 (0.074)----Cont. Loss 0.0339 (0.0378)----Adv. Loss 1.0438 (1.2281)----Disc. Loss 1.4612 (1.5979)\n",
      "Epoch: [3][33/36]----Batch Time 0.456 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0387 (0.0378)----Adv. Loss 1.0020 (1.2214)----Disc. Loss 1.4409 (1.5933)\n",
      "Epoch: [3][34/36]----Batch Time 0.458 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0335 (0.0377)----Adv. Loss 0.8963 (1.2121)----Disc. Loss 1.3900 (1.5875)\n",
      "Epoch: [3][35/36]----Batch Time 0.344 (0.454)----Data Time 0.054 (0.074)----Cont. Loss 0.0362 (0.0376)----Adv. Loss 0.8205 (1.2042)----Disc. Loss 1.3867 (1.5834)\n",
      "Epoch: [4][0/36]----Batch Time 0.469 (0.469)----Data Time 0.075 (0.075)----Cont. Loss 0.0350 (0.0350)----Adv. Loss 0.6690 (0.6690)----Disc. Loss 1.3703 (1.3703)\n",
      "Epoch: [4][1/36]----Batch Time 0.455 (0.462)----Data Time 0.075 (0.075)----Cont. Loss 0.0357 (0.0354)----Adv. Loss 0.6314 (0.6502)----Disc. Loss 1.3708 (1.3706)\n",
      "Epoch: [4][2/36]----Batch Time 0.459 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0397 (0.0368)----Adv. Loss 0.5899 (0.6301)----Disc. Loss 1.3907 (1.3773)\n",
      "Epoch: [4][3/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0408 (0.0378)----Adv. Loss 0.5512 (0.6104)----Disc. Loss 1.4062 (1.3845)\n",
      "Epoch: [4][4/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0344 (0.0371)----Adv. Loss 0.5649 (0.6013)----Disc. Loss 1.3903 (1.3857)\n",
      "Epoch: [4][5/36]----Batch Time 0.456 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0402 (0.0376)----Adv. Loss 0.6243 (0.6051)----Disc. Loss 1.3685 (1.3828)\n",
      "Epoch: [4][6/36]----Batch Time 0.458 (0.458)----Data Time 0.077 (0.075)----Cont. Loss 0.0348 (0.0372)----Adv. Loss 0.6392 (0.6100)----Disc. Loss 1.3577 (1.3792)\n",
      "Epoch: [4][7/36]----Batch Time 0.456 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0337 (0.0368)----Adv. Loss 0.7025 (0.6216)----Disc. Loss 1.3516 (1.3758)\n",
      "Epoch: [4][8/36]----Batch Time 0.454 (0.458)----Data Time 0.074 (0.075)----Cont. Loss 0.0422 (0.0374)----Adv. Loss 0.7531 (0.6362)----Disc. Loss 1.3377 (1.3715)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][9/36]----Batch Time 0.458 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0402 (0.0377)----Adv. Loss 0.8319 (0.6557)----Disc. Loss 1.3473 (1.3691)\n",
      "Epoch: [4][10/36]----Batch Time 0.456 (0.458)----Data Time 0.074 (0.075)----Cont. Loss 0.0358 (0.0375)----Adv. Loss 0.8523 (0.6736)----Disc. Loss 1.3438 (1.3668)\n",
      "Epoch: [4][11/36]----Batch Time 0.457 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0345 (0.0373)----Adv. Loss 0.9148 (0.6937)----Disc. Loss 1.3432 (1.3648)\n",
      "Epoch: [4][12/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0342 (0.0370)----Adv. Loss 0.8499 (0.7057)----Disc. Loss 1.3341 (1.3625)\n",
      "Epoch: [4][13/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0341 (0.0368)----Adv. Loss 0.7981 (0.7123)----Disc. Loss 1.3126 (1.3589)\n",
      "Epoch: [4][14/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.075)----Cont. Loss 0.0323 (0.0365)----Adv. Loss 0.7424 (0.7143)----Disc. Loss 1.2796 (1.3536)\n",
      "Epoch: [4][15/36]----Batch Time 0.458 (0.457)----Data Time 0.077 (0.075)----Cont. Loss 0.0362 (0.0365)----Adv. Loss 0.7294 (0.7153)----Disc. Loss 1.2880 (1.3495)\n",
      "Epoch: [4][16/36]----Batch Time 0.457 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0372 (0.0365)----Adv. Loss 0.6979 (0.7142)----Disc. Loss 1.2995 (1.3466)\n",
      "Epoch: [4][17/36]----Batch Time 0.456 (0.457)----Data Time 0.073 (0.075)----Cont. Loss 0.0365 (0.0365)----Adv. Loss 0.6965 (0.7133)----Disc. Loss 1.2536 (1.3414)\n",
      "Epoch: [4][18/36]----Batch Time 0.455 (0.457)----Data Time 0.073 (0.075)----Cont. Loss 0.0360 (0.0365)----Adv. Loss 0.7235 (0.7138)----Disc. Loss 1.2334 (1.3357)\n",
      "Epoch: [4][19/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0364 (0.0365)----Adv. Loss 0.7440 (0.7153)----Disc. Loss 1.2081 (1.3293)\n",
      "Epoch: [4][20/36]----Batch Time 0.456 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0403 (0.0367)----Adv. Loss 0.8120 (0.7199)----Disc. Loss 1.2169 (1.3240)\n",
      "Epoch: [4][21/36]----Batch Time 0.457 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0385 (0.0368)----Adv. Loss 0.8560 (0.7261)----Disc. Loss 1.1766 (1.3173)\n",
      "Epoch: [4][22/36]----Batch Time 0.457 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0348 (0.0367)----Adv. Loss 0.9102 (0.7341)----Disc. Loss 1.1651 (1.3107)\n",
      "Epoch: [4][23/36]----Batch Time 0.457 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0345 (0.0366)----Adv. Loss 0.9500 (0.7431)----Disc. Loss 1.1102 (1.3023)\n",
      "Epoch: [4][24/36]----Batch Time 0.459 (0.457)----Data Time 0.076 (0.075)----Cont. Loss 0.0445 (0.0369)----Adv. Loss 0.9195 (0.7502)----Disc. Loss 1.0480 (1.2922)\n",
      "Epoch: [4][25/36]----Batch Time 0.457 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0393 (0.0370)----Adv. Loss 0.9581 (0.7582)----Disc. Loss 0.9996 (1.2809)\n",
      "Epoch: [4][26/36]----Batch Time 0.456 (0.457)----Data Time 0.073 (0.074)----Cont. Loss 0.0430 (0.0372)----Adv. Loss 0.9234 (0.7643)----Disc. Loss 0.9417 (1.2683)\n",
      "Epoch: [4][27/36]----Batch Time 0.462 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0456 (0.0375)----Adv. Loss 1.0651 (0.7750)----Disc. Loss 0.8074 (1.2519)\n",
      "Epoch: [4][28/36]----Batch Time 0.462 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0363 (0.0375)----Adv. Loss 1.1938 (0.7895)----Disc. Loss 0.7854 (1.2358)\n",
      "Epoch: [4][29/36]----Batch Time 0.456 (0.457)----Data Time 0.074 (0.074)----Cont. Loss 0.0365 (0.0374)----Adv. Loss 1.3565 (0.8084)----Disc. Loss 0.6463 (1.2161)\n",
      "Epoch: [4][30/36]----Batch Time 0.458 (0.457)----Data Time 0.076 (0.074)----Cont. Loss 0.0371 (0.0374)----Adv. Loss 1.5755 (0.8331)----Disc. Loss 0.5259 (1.1939)\n",
      "Epoch: [4][31/36]----Batch Time 0.460 (0.457)----Data Time 0.075 (0.074)----Cont. Loss 0.0332 (0.0373)----Adv. Loss 1.7371 (0.8614)----Disc. Loss 0.4339 (1.1701)\n",
      "Epoch: [4][32/36]----Batch Time 0.461 (0.457)----Data Time 0.075 (0.075)----Cont. Loss 0.0358 (0.0373)----Adv. Loss 1.7221 (0.8874)----Disc. Loss 0.3490 (1.1452)\n",
      "Epoch: [4][33/36]----Batch Time 0.474 (0.458)----Data Time 0.090 (0.075)----Cont. Loss 0.0391 (0.0373)----Adv. Loss 1.9370 (0.9183)----Disc. Loss 0.2752 (1.1197)\n",
      "Epoch: [4][34/36]----Batch Time 0.459 (0.458)----Data Time 0.075 (0.075)----Cont. Loss 0.0395 (0.0374)----Adv. Loss 2.1864 (0.9545)----Disc. Loss 0.2046 (1.0935)\n",
      "Epoch: [4][35/36]----Batch Time 0.347 (0.455)----Data Time 0.054 (0.074)----Cont. Loss 0.0352 (0.0373)----Adv. Loss 2.9602 (0.9949)----Disc. Loss 0.1487 (1.0745)\n",
      "Epoch: [5][0/36]----Batch Time 0.476 (0.476)----Data Time 0.074 (0.074)----Cont. Loss 0.0406 (0.0406)----Adv. Loss 3.1789 (3.1789)----Disc. Loss 0.0939 (0.0939)\n",
      "Epoch: [5][1/36]----Batch Time 0.458 (0.467)----Data Time 0.074 (0.074)----Cont. Loss 0.0312 (0.0359)----Adv. Loss 3.5818 (3.3803)----Disc. Loss 0.1064 (0.1002)\n",
      "Epoch: [5][2/36]----Batch Time 0.458 (0.464)----Data Time 0.074 (0.074)----Cont. Loss 0.0399 (0.0372)----Adv. Loss 3.4450 (3.4019)----Disc. Loss 0.0670 (0.0891)\n",
      "Epoch: [5][3/36]----Batch Time 0.458 (0.462)----Data Time 0.075 (0.074)----Cont. Loss 0.0385 (0.0375)----Adv. Loss 3.4084 (3.4035)----Disc. Loss 0.0639 (0.0828)\n",
      "Epoch: [5][4/36]----Batch Time 0.460 (0.462)----Data Time 0.075 (0.074)----Cont. Loss 0.0344 (0.0369)----Adv. Loss 3.5851 (3.4398)----Disc. Loss 0.0617 (0.0786)\n",
      "Epoch: [5][5/36]----Batch Time 0.457 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0384 (0.0372)----Adv. Loss 3.7300 (3.4882)----Disc. Loss 0.0917 (0.0808)\n",
      "Epoch: [5][6/36]----Batch Time 0.458 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0378 (0.0373)----Adv. Loss 3.6858 (3.5164)----Disc. Loss 0.0838 (0.0812)\n",
      "Epoch: [5][7/36]----Batch Time 0.469 (0.462)----Data Time 0.074 (0.074)----Cont. Loss 0.0349 (0.0370)----Adv. Loss 2.7787 (3.4242)----Disc. Loss 0.2609 (0.1037)\n",
      "Epoch: [5][8/36]----Batch Time 0.462 (0.462)----Data Time 0.075 (0.074)----Cont. Loss 0.0418 (0.0375)----Adv. Loss 2.6897 (3.3426)----Disc. Loss 2.1257 (0.3283)\n",
      "Epoch: [5][9/36]----Batch Time 0.457 (0.461)----Data Time 0.075 (0.074)----Cont. Loss 0.0401 (0.0378)----Adv. Loss 0.0022 (3.0086)----Disc. Loss 8.5778 (1.1533)\n",
      "Epoch: [5][10/36]----Batch Time 0.464 (0.461)----Data Time 0.077 (0.074)----Cont. Loss 0.0344 (0.0375)----Adv. Loss 0.0946 (2.7437)----Disc. Loss 5.0962 (1.5117)\n",
      "Epoch: [5][11/36]----Batch Time 0.470 (0.462)----Data Time 0.075 (0.074)----Cont. Loss 0.0427 (0.0379)----Adv. Loss 1.4603 (2.6367)----Disc. Loss 3.8618 (1.7076)\n",
      "Epoch: [5][12/36]----Batch Time 0.458 (0.462)----Data Time 0.074 (0.074)----Cont. Loss 0.0337 (0.0376)----Adv. Loss 1.9537 (2.5842)----Disc. Loss 3.7786 (1.8669)\n",
      "Epoch: [5][13/36]----Batch Time 0.460 (0.462)----Data Time 0.075 (0.074)----Cont. Loss 0.0326 (0.0372)----Adv. Loss 2.3962 (2.5707)----Disc. Loss 3.5075 (1.9841)\n",
      "Epoch: [5][14/36]----Batch Time 0.462 (0.462)----Data Time 0.076 (0.075)----Cont. Loss 0.0403 (0.0374)----Adv. Loss 2.1677 (2.5439)----Disc. Loss 3.0328 (2.0540)\n",
      "Epoch: [5][15/36]----Batch Time 0.460 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0380 (0.0375)----Adv. Loss 1.6576 (2.4885)----Disc. Loss 2.3773 (2.0742)\n",
      "Epoch: [5][16/36]----Batch Time 0.455 (0.461)----Data Time 0.073 (0.074)----Cont. Loss 0.0381 (0.0375)----Adv. Loss 1.0886 (2.4061)----Disc. Loss 1.8673 (2.0620)\n",
      "Epoch: [5][17/36]----Batch Time 0.458 (0.461)----Data Time 0.075 (0.074)----Cont. Loss 0.0406 (0.0377)----Adv. Loss 0.7721 (2.3154)----Disc. Loss 1.6305 (2.0381)\n",
      "Epoch: [5][18/36]----Batch Time 0.455 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0419 (0.0379)----Adv. Loss 0.4450 (2.2169)----Disc. Loss 1.6447 (2.0174)\n",
      "Epoch: [5][19/36]----Batch Time 0.456 (0.460)----Data Time 0.075 (0.074)----Cont. Loss 0.0404 (0.0380)----Adv. Loss 0.3293 (2.1225)----Disc. Loss 1.7654 (2.0048)\n",
      "Epoch: [5][20/36]----Batch Time 0.460 (0.460)----Data Time 0.074 (0.074)----Cont. Loss 0.0395 (0.0381)----Adv. Loss 0.2482 (2.0333)----Disc. Loss 1.8983 (1.9997)\n",
      "Epoch: [5][21/36]----Batch Time 0.459 (0.460)----Data Time 0.077 (0.075)----Cont. Loss 0.0355 (0.0380)----Adv. Loss 0.2467 (1.9521)----Disc. Loss 1.9041 (1.9953)\n",
      "Epoch: [5][22/36]----Batch Time 0.459 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0411 (0.0381)----Adv. Loss 0.2797 (1.8794)----Disc. Loss 1.8309 (1.9882)\n",
      "Epoch: [5][23/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0381 (0.0381)----Adv. Loss 0.3714 (1.8165)----Disc. Loss 1.7087 (1.9765)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][24/36]----Batch Time 0.456 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0341 (0.0379)----Adv. Loss 0.4521 (1.7620)----Disc. Loss 1.5894 (1.9611)\n",
      "Epoch: [5][25/36]----Batch Time 0.457 (0.460)----Data Time 0.074 (0.074)----Cont. Loss 0.0380 (0.0379)----Adv. Loss 0.6186 (1.7180)----Disc. Loss 1.4982 (1.9433)\n",
      "Epoch: [5][26/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0397 (0.0380)----Adv. Loss 0.8539 (1.6860)----Disc. Loss 1.4935 (1.9266)\n",
      "Epoch: [5][27/36]----Batch Time 0.456 (0.460)----Data Time 0.074 (0.074)----Cont. Loss 0.0329 (0.0378)----Adv. Loss 0.9836 (1.6609)----Disc. Loss 1.4881 (1.9109)\n",
      "Epoch: [5][28/36]----Batch Time 0.461 (0.460)----Data Time 0.075 (0.074)----Cont. Loss 0.0319 (0.0376)----Adv. Loss 1.1425 (1.6430)----Disc. Loss 1.5560 (1.8987)\n",
      "Epoch: [5][29/36]----Batch Time 0.459 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0389 (0.0377)----Adv. Loss 1.2065 (1.6285)----Disc. Loss 1.5600 (1.8874)\n",
      "Epoch: [5][30/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0348 (0.0376)----Adv. Loss 1.2393 (1.6159)----Disc. Loss 1.5704 (1.8772)\n",
      "Epoch: [5][31/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0354 (0.0375)----Adv. Loss 1.1219 (1.6005)----Disc. Loss 1.5079 (1.8656)\n",
      "Epoch: [5][32/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0375 (0.0375)----Adv. Loss 1.0442 (1.5836)----Disc. Loss 1.4584 (1.8533)\n",
      "Epoch: [5][33/36]----Batch Time 0.461 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0388 (0.0375)----Adv. Loss 0.8339 (1.5616)----Disc. Loss 1.3896 (1.8397)\n",
      "Epoch: [5][34/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0420 (0.0377)----Adv. Loss 0.7371 (1.5380)----Disc. Loss 1.4091 (1.8274)\n",
      "Epoch: [5][35/36]----Batch Time 0.341 (0.456)----Data Time 0.055 (0.074)----Cont. Loss 0.0370 (0.0377)----Adv. Loss 0.6158 (1.5195)----Disc. Loss 1.4433 (1.8196)\n",
      "Epoch: [6][0/36]----Batch Time 0.486 (0.486)----Data Time 0.074 (0.074)----Cont. Loss 0.0338 (0.0338)----Adv. Loss 0.5391 (0.5391)----Disc. Loss 1.4379 (1.4379)\n",
      "Epoch: [6][1/36]----Batch Time 0.457 (0.471)----Data Time 0.075 (0.074)----Cont. Loss 0.0407 (0.0373)----Adv. Loss 0.5233 (0.5312)----Disc. Loss 1.4527 (1.4453)\n",
      "Epoch: [6][2/36]----Batch Time 0.458 (0.467)----Data Time 0.076 (0.075)----Cont. Loss 0.0374 (0.0373)----Adv. Loss 0.5101 (0.5241)----Disc. Loss 1.4461 (1.4456)\n",
      "Epoch: [6][3/36]----Batch Time 0.459 (0.465)----Data Time 0.076 (0.075)----Cont. Loss 0.0361 (0.0370)----Adv. Loss 0.5317 (0.5260)----Disc. Loss 1.4078 (1.4361)\n",
      "Epoch: [6][4/36]----Batch Time 0.458 (0.463)----Data Time 0.076 (0.075)----Cont. Loss 0.0392 (0.0374)----Adv. Loss 0.5776 (0.5363)----Disc. Loss 1.3969 (1.4283)\n",
      "Epoch: [6][5/36]----Batch Time 0.478 (0.466)----Data Time 0.075 (0.075)----Cont. Loss 0.0408 (0.0380)----Adv. Loss 0.6913 (0.5622)----Disc. Loss 1.3573 (1.4164)\n",
      "Epoch: [6][6/36]----Batch Time 0.455 (0.464)----Data Time 0.074 (0.075)----Cont. Loss 0.0308 (0.0370)----Adv. Loss 0.7792 (0.5932)----Disc. Loss 1.3555 (1.4077)\n",
      "Epoch: [6][7/36]----Batch Time 0.461 (0.464)----Data Time 0.075 (0.075)----Cont. Loss 0.0378 (0.0371)----Adv. Loss 0.7923 (0.6181)----Disc. Loss 1.3497 (1.4005)\n",
      "Epoch: [6][8/36]----Batch Time 0.456 (0.463)----Data Time 0.074 (0.075)----Cont. Loss 0.0336 (0.0367)----Adv. Loss 0.8501 (0.6438)----Disc. Loss 1.3721 (1.3973)\n",
      "Epoch: [6][9/36]----Batch Time 0.460 (0.463)----Data Time 0.077 (0.075)----Cont. Loss 0.0373 (0.0367)----Adv. Loss 0.8423 (0.6637)----Disc. Loss 1.3680 (1.3944)\n",
      "Epoch: [6][10/36]----Batch Time 0.457 (0.462)----Data Time 0.074 (0.075)----Cont. Loss 0.0338 (0.0365)----Adv. Loss 0.9142 (0.6865)----Disc. Loss 1.3673 (1.3919)\n",
      "Epoch: [6][11/36]----Batch Time 0.463 (0.462)----Data Time 0.076 (0.075)----Cont. Loss 0.0352 (0.0364)----Adv. Loss 0.8968 (0.7040)----Disc. Loss 1.3339 (1.3871)\n",
      "Epoch: [6][12/36]----Batch Time 0.456 (0.462)----Data Time 0.075 (0.075)----Cont. Loss 0.0304 (0.0359)----Adv. Loss 0.8421 (0.7146)----Disc. Loss 1.3166 (1.3817)\n",
      "Epoch: [6][13/36]----Batch Time 0.461 (0.462)----Data Time 0.076 (0.075)----Cont. Loss 0.0354 (0.0359)----Adv. Loss 0.8011 (0.7208)----Disc. Loss 1.3128 (1.3768)\n",
      "Epoch: [6][14/36]----Batch Time 0.456 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0299 (0.0355)----Adv. Loss 0.7625 (0.7236)----Disc. Loss 1.2982 (1.3715)\n",
      "Epoch: [6][15/36]----Batch Time 0.457 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0328 (0.0353)----Adv. Loss 0.7731 (0.7267)----Disc. Loss 1.3087 (1.3676)\n",
      "Epoch: [6][16/36]----Batch Time 0.458 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0427 (0.0357)----Adv. Loss 0.7305 (0.7269)----Disc. Loss 1.2964 (1.3634)\n",
      "Epoch: [6][17/36]----Batch Time 0.460 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0397 (0.0360)----Adv. Loss 0.6933 (0.7250)----Disc. Loss 1.3240 (1.3612)\n",
      "Epoch: [6][18/36]----Batch Time 0.459 (0.461)----Data Time 0.076 (0.075)----Cont. Loss 0.0308 (0.0357)----Adv. Loss 0.7321 (0.7254)----Disc. Loss 1.2933 (1.3576)\n",
      "Epoch: [6][19/36]----Batch Time 0.461 (0.461)----Data Time 0.076 (0.075)----Cont. Loss 0.0352 (0.0357)----Adv. Loss 0.7460 (0.7264)----Disc. Loss 1.2616 (1.3528)\n",
      "Epoch: [6][20/36]----Batch Time 0.460 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0341 (0.0356)----Adv. Loss 0.7948 (0.7297)----Disc. Loss 1.2201 (1.3465)\n",
      "Epoch: [6][21/36]----Batch Time 0.459 (0.460)----Data Time 0.073 (0.075)----Cont. Loss 0.0329 (0.0355)----Adv. Loss 0.8181 (0.7337)----Disc. Loss 1.2436 (1.3418)\n",
      "Epoch: [6][22/36]----Batch Time 0.457 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0347 (0.0354)----Adv. Loss 0.8508 (0.7388)----Disc. Loss 1.1960 (1.3355)\n",
      "Epoch: [6][23/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0337 (0.0354)----Adv. Loss 0.8275 (0.7425)----Disc. Loss 1.1951 (1.3296)\n",
      "Epoch: [6][24/36]----Batch Time 0.458 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0374 (0.0354)----Adv. Loss 0.9171 (0.7495)----Disc. Loss 1.1638 (1.3230)\n",
      "Epoch: [6][25/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0341 (0.0354)----Adv. Loss 0.8959 (0.7551)----Disc. Loss 1.1728 (1.3172)\n",
      "Epoch: [6][26/36]----Batch Time 0.458 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0344 (0.0354)----Adv. Loss 0.9019 (0.7605)----Disc. Loss 1.0917 (1.3089)\n",
      "Epoch: [6][27/36]----Batch Time 0.459 (0.460)----Data Time 0.077 (0.075)----Cont. Loss 0.0359 (0.0354)----Adv. Loss 0.9768 (0.7683)----Disc. Loss 1.0645 (1.3002)\n",
      "Epoch: [6][28/36]----Batch Time 0.455 (0.460)----Data Time 0.073 (0.075)----Cont. Loss 0.0395 (0.0355)----Adv. Loss 0.9422 (0.7743)----Disc. Loss 1.0273 (1.2907)\n",
      "Epoch: [6][29/36]----Batch Time 0.456 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0323 (0.0354)----Adv. Loss 1.0152 (0.7823)----Disc. Loss 1.0046 (1.2812)\n",
      "Epoch: [6][30/36]----Batch Time 0.458 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0352 (0.0354)----Adv. Loss 0.9327 (0.7871)----Disc. Loss 0.9308 (1.2699)\n",
      "Epoch: [6][31/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0370 (0.0355)----Adv. Loss 1.0404 (0.7951)----Disc. Loss 0.8562 (1.2570)\n",
      "Epoch: [6][32/36]----Batch Time 0.458 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0349 (0.0354)----Adv. Loss 1.1083 (0.8046)----Disc. Loss 0.7813 (1.2426)\n",
      "Epoch: [6][33/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0309 (0.0353)----Adv. Loss 1.1857 (0.8158)----Disc. Loss 0.7103 (1.2269)\n",
      "Epoch: [6][34/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0390 (0.0354)----Adv. Loss 1.3953 (0.8323)----Disc. Loss 0.6643 (1.2108)\n",
      "Epoch: [6][35/36]----Batch Time 0.344 (0.456)----Data Time 0.054 (0.074)----Cont. Loss 0.0317 (0.0353)----Adv. Loss 1.6885 (0.8495)----Disc. Loss 0.5608 (1.1977)\n",
      "Epoch: [7][0/36]----Batch Time 0.481 (0.481)----Data Time 0.076 (0.076)----Cont. Loss 0.0374 (0.0374)----Adv. Loss 1.7489 (1.7489)----Disc. Loss 0.5507 (0.5507)\n",
      "Epoch: [7][1/36]----Batch Time 0.456 (0.468)----Data Time 0.075 (0.075)----Cont. Loss 0.0364 (0.0369)----Adv. Loss 1.7582 (1.7536)----Disc. Loss 0.4478 (0.4993)\n",
      "Epoch: [7][2/36]----Batch Time 0.459 (0.465)----Data Time 0.076 (0.075)----Cont. Loss 0.0341 (0.0360)----Adv. Loss 2.0090 (1.8387)----Disc. Loss 0.4234 (0.4740)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][3/36]----Batch Time 0.457 (0.463)----Data Time 0.075 (0.075)----Cont. Loss 0.0415 (0.0373)----Adv. Loss 2.4043 (1.9801)----Disc. Loss 0.3105 (0.4331)\n",
      "Epoch: [7][4/36]----Batch Time 0.457 (0.462)----Data Time 0.075 (0.075)----Cont. Loss 0.0360 (0.0371)----Adv. Loss 2.3141 (2.0469)----Disc. Loss 0.2707 (0.4006)\n",
      "Epoch: [7][5/36]----Batch Time 0.457 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0356 (0.0368)----Adv. Loss 2.5648 (2.1332)----Disc. Loss 0.2240 (0.3712)\n",
      "Epoch: [7][6/36]----Batch Time 0.461 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0383 (0.0370)----Adv. Loss 2.6369 (2.2052)----Disc. Loss 0.1855 (0.3446)\n",
      "Epoch: [7][7/36]----Batch Time 0.462 (0.461)----Data Time 0.075 (0.075)----Cont. Loss 0.0329 (0.0365)----Adv. Loss 2.8851 (2.2902)----Disc. Loss 0.1413 (0.3192)\n",
      "Epoch: [7][8/36]----Batch Time 0.456 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0343 (0.0363)----Adv. Loss 3.5203 (2.4268)----Disc. Loss 0.1172 (0.2968)\n",
      "Epoch: [7][9/36]----Batch Time 0.460 (0.460)----Data Time 0.077 (0.075)----Cont. Loss 0.0292 (0.0356)----Adv. Loss 3.7010 (2.5543)----Disc. Loss 0.0750 (0.2746)\n",
      "Epoch: [7][10/36]----Batch Time 0.460 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0379 (0.0358)----Adv. Loss 4.0853 (2.6934)----Disc. Loss 0.0531 (0.2545)\n",
      "Epoch: [7][11/36]----Batch Time 0.457 (0.460)----Data Time 0.074 (0.075)----Cont. Loss 0.0382 (0.0360)----Adv. Loss 4.2661 (2.8245)----Disc. Loss 0.0535 (0.2377)\n",
      "Epoch: [7][12/36]----Batch Time 0.458 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0377 (0.0361)----Adv. Loss 3.8077 (2.9001)----Disc. Loss 0.0635 (0.2243)\n",
      "Epoch: [7][13/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0301 (0.0357)----Adv. Loss 4.0707 (2.9837)----Disc. Loss 0.0498 (0.2118)\n",
      "Epoch: [7][14/36]----Batch Time 0.461 (0.460)----Data Time 0.076 (0.075)----Cont. Loss 0.0370 (0.0358)----Adv. Loss 3.7150 (3.0325)----Disc. Loss 0.0626 (0.2019)\n",
      "Epoch: [7][15/36]----Batch Time 0.455 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0378 (0.0359)----Adv. Loss 4.0268 (3.0946)----Disc. Loss 0.0519 (0.1925)\n",
      "Epoch: [7][16/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0348 (0.0358)----Adv. Loss 4.2353 (3.1617)----Disc. Loss 0.0496 (0.1841)\n",
      "Epoch: [7][17/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0387 (0.0360)----Adv. Loss 4.3047 (3.2252)----Disc. Loss 0.0934 (0.1791)\n",
      "Epoch: [7][18/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0394 (0.0362)----Adv. Loss 3.8224 (3.2567)----Disc. Loss 0.0770 (0.1737)\n",
      "Epoch: [7][19/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0364 (0.0362)----Adv. Loss 4.2568 (3.3067)----Disc. Loss 0.0548 (0.1678)\n",
      "Epoch: [7][20/36]----Batch Time 0.458 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0335 (0.0361)----Adv. Loss 4.0847 (3.3437)----Disc. Loss 0.0655 (0.1629)\n",
      "Epoch: [7][21/36]----Batch Time 0.460 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0378 (0.0361)----Adv. Loss 3.7596 (3.3626)----Disc. Loss 0.1225 (0.1611)\n",
      "Epoch: [7][22/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0351 (0.0361)----Adv. Loss 2.6331 (3.3309)----Disc. Loss 0.3753 (0.1704)\n",
      "Epoch: [7][23/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0396 (0.0362)----Adv. Loss 2.8698 (3.3117)----Disc. Loss 0.6580 (0.1907)\n",
      "Epoch: [7][24/36]----Batch Time 0.459 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0372 (0.0363)----Adv. Loss 3.9895 (3.3388)----Disc. Loss 0.3112 (0.1955)\n",
      "Epoch: [7][25/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0353 (0.0362)----Adv. Loss 1.3311 (3.2616)----Disc. Loss 1.1302 (0.2315)\n",
      "Epoch: [7][26/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0362 (0.0362)----Adv. Loss 3.7745 (3.2806)----Disc. Loss 0.2929 (0.2337)\n",
      "Epoch: [7][27/36]----Batch Time 0.461 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0387 (0.0363)----Adv. Loss 4.7114 (3.3317)----Disc. Loss 1.6657 (0.2849)\n",
      "Epoch: [7][28/36]----Batch Time 0.458 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0355 (0.0363)----Adv. Loss 2.0234 (3.2866)----Disc. Loss 0.4493 (0.2906)\n",
      "Epoch: [7][29/36]----Batch Time 0.460 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0385 (0.0364)----Adv. Loss 0.5721 (3.1961)----Disc. Loss 1.7813 (0.3402)\n",
      "Epoch: [7][30/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0402 (0.0365)----Adv. Loss 2.0866 (3.1603)----Disc. Loss 0.4207 (0.3428)\n",
      "Epoch: [7][31/36]----Batch Time 0.458 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0339 (0.0364)----Adv. Loss 5.0717 (3.2200)----Disc. Loss 0.8950 (0.3601)\n",
      "Epoch: [7][32/36]----Batch Time 0.461 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0378 (0.0365)----Adv. Loss 4.9074 (3.2712)----Disc. Loss 1.0356 (0.3806)\n",
      "Epoch: [7][33/36]----Batch Time 0.459 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0393 (0.0365)----Adv. Loss 2.9901 (3.2629)----Disc. Loss 0.3636 (0.3801)\n",
      "Epoch: [7][34/36]----Batch Time 0.458 (0.459)----Data Time 0.073 (0.075)----Cont. Loss 0.0396 (0.0366)----Adv. Loss 2.7133 (3.2472)----Disc. Loss 0.2640 (0.3768)\n",
      "Epoch: [7][35/36]----Batch Time 0.345 (0.455)----Data Time 0.054 (0.074)----Cont. Loss 0.0348 (0.0366)----Adv. Loss 1.6094 (3.2142)----Disc. Loss 0.4319 (0.3779)\n",
      "Epoch: [8][0/36]----Batch Time 0.470 (0.470)----Data Time 0.076 (0.076)----Cont. Loss 0.0376 (0.0376)----Adv. Loss 0.7997 (0.7997)----Disc. Loss 0.9550 (0.9550)\n",
      "Epoch: [8][1/36]----Batch Time 0.457 (0.463)----Data Time 0.075 (0.075)----Cont. Loss 0.0334 (0.0355)----Adv. Loss 1.8432 (1.3214)----Disc. Loss 0.3594 (0.6572)\n",
      "Epoch: [8][2/36]----Batch Time 0.457 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0328 (0.0346)----Adv. Loss 2.2413 (1.6281)----Disc. Loss 0.2758 (0.5301)\n",
      "Epoch: [8][3/36]----Batch Time 0.461 (0.461)----Data Time 0.076 (0.075)----Cont. Loss 0.0341 (0.0345)----Adv. Loss 3.4438 (2.0820)----Disc. Loss 0.3152 (0.4763)\n",
      "Epoch: [8][4/36]----Batch Time 0.460 (0.461)----Data Time 0.074 (0.075)----Cont. Loss 0.0414 (0.0358)----Adv. Loss 3.5168 (2.3689)----Disc. Loss 0.3527 (0.4516)\n",
      "Epoch: [8][5/36]----Batch Time 0.457 (0.460)----Data Time 0.075 (0.075)----Cont. Loss 0.0367 (0.0360)----Adv. Loss 3.8842 (2.6215)----Disc. Loss 0.4455 (0.4506)\n",
      "Epoch: [8][6/36]----Batch Time 0.456 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0330 (0.0356)----Adv. Loss 3.9219 (2.8073)----Disc. Loss 0.4229 (0.4466)\n",
      "Epoch: [8][7/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0360 (0.0356)----Adv. Loss 2.8713 (2.8153)----Disc. Loss 0.2458 (0.4215)\n",
      "Epoch: [8][8/36]----Batch Time 0.455 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0335 (0.0354)----Adv. Loss 2.0854 (2.7342)----Disc. Loss 0.2945 (0.4074)\n",
      "Epoch: [8][9/36]----Batch Time 0.464 (0.459)----Data Time 0.077 (0.075)----Cont. Loss 0.0336 (0.0352)----Adv. Loss 1.6708 (2.6278)----Disc. Loss 0.5257 (0.4192)\n",
      "Epoch: [8][10/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0387 (0.0355)----Adv. Loss 1.5861 (2.5331)----Disc. Loss 0.4635 (0.4233)\n",
      "Epoch: [8][11/36]----Batch Time 0.462 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0379 (0.0357)----Adv. Loss 3.1612 (2.5855)----Disc. Loss 0.2782 (0.4112)\n",
      "Epoch: [8][12/36]----Batch Time 0.458 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0370 (0.0358)----Adv. Loss 3.4412 (2.6513)----Disc. Loss 0.3446 (0.4061)\n",
      "Epoch: [8][13/36]----Batch Time 0.459 (0.459)----Data Time 0.073 (0.075)----Cont. Loss 0.0447 (0.0365)----Adv. Loss 3.3028 (2.6978)----Disc. Loss 0.2124 (0.3922)\n",
      "Epoch: [8][14/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0387 (0.0366)----Adv. Loss 2.5099 (2.6853)----Disc. Loss 0.2149 (0.3804)\n",
      "Epoch: [8][15/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0397 (0.0368)----Adv. Loss 2.9620 (2.7026)----Disc. Loss 0.2274 (0.3708)\n",
      "Epoch: [8][16/36]----Batch Time 0.464 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0366 (0.0368)----Adv. Loss 3.0351 (2.7222)----Disc. Loss 0.1527 (0.3580)\n",
      "Epoch: [8][17/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0415 (0.0370)----Adv. Loss 3.3015 (2.7543)----Disc. Loss 0.1117 (0.3443)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][18/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0373 (0.0371)----Adv. Loss 4.1382 (2.8272)----Disc. Loss 0.0963 (0.3313)\n",
      "Epoch: [8][19/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0348 (0.0369)----Adv. Loss 4.2538 (2.8985)----Disc. Loss 0.1065 (0.3200)\n",
      "Epoch: [8][20/36]----Batch Time 0.458 (0.459)----Data Time 0.073 (0.075)----Cont. Loss 0.0325 (0.0367)----Adv. Loss 4.1836 (2.9597)----Disc. Loss 0.0519 (0.3073)\n",
      "Epoch: [8][21/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0324 (0.0365)----Adv. Loss 4.5089 (3.0301)----Disc. Loss 0.0339 (0.2948)\n",
      "Epoch: [8][22/36]----Batch Time 0.461 (0.459)----Data Time 0.073 (0.074)----Cont. Loss 0.0359 (0.0365)----Adv. Loss 4.9194 (3.1123)----Disc. Loss 0.0539 (0.2844)\n",
      "Epoch: [8][23/36]----Batch Time 0.456 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0354 (0.0365)----Adv. Loss 4.5031 (3.1702)----Disc. Loss 0.0246 (0.2735)\n",
      "Epoch: [8][24/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0421 (0.0367)----Adv. Loss 3.5556 (3.1856)----Disc. Loss 0.0781 (0.2657)\n",
      "Epoch: [8][25/36]----Batch Time 0.457 (0.459)----Data Time 0.076 (0.074)----Cont. Loss 0.0426 (0.0369)----Adv. Loss 3.4379 (3.1953)----Disc. Loss 0.0536 (0.2576)\n",
      "Epoch: [8][26/36]----Batch Time 0.460 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0396 (0.0370)----Adv. Loss 3.7583 (3.2162)----Disc. Loss 0.0541 (0.2500)\n",
      "Epoch: [8][27/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0355 (0.0370)----Adv. Loss 2.2569 (3.1819)----Disc. Loss 0.3089 (0.2521)\n",
      "Epoch: [8][28/36]----Batch Time 0.456 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0327 (0.0368)----Adv. Loss 3.3003 (3.1860)----Disc. Loss 0.1239 (0.2477)\n",
      "Epoch: [8][29/36]----Batch Time 0.458 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0355 (0.0368)----Adv. Loss 3.5852 (3.1993)----Disc. Loss 0.1922 (0.2459)\n",
      "Epoch: [8][30/36]----Batch Time 0.456 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0423 (0.0369)----Adv. Loss 2.2527 (3.1688)----Disc. Loss 0.8350 (0.2649)\n",
      "Epoch: [8][31/36]----Batch Time 0.457 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0347 (0.0369)----Adv. Loss 1.5963 (3.1196)----Disc. Loss 1.0037 (0.2880)\n",
      "Epoch: [8][32/36]----Batch Time 0.456 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0355 (0.0368)----Adv. Loss 1.6000 (3.0736)----Disc. Loss 0.8380 (0.3046)\n",
      "Epoch: [8][33/36]----Batch Time 0.457 (0.458)----Data Time 0.074 (0.074)----Cont. Loss 0.0393 (0.0369)----Adv. Loss 2.9886 (3.0711)----Disc. Loss 0.8871 (0.3217)\n",
      "Epoch: [8][34/36]----Batch Time 0.458 (0.458)----Data Time 0.075 (0.074)----Cont. Loss 0.0330 (0.0368)----Adv. Loss 1.2686 (3.0196)----Disc. Loss 0.6262 (0.3304)\n",
      "Epoch: [8][35/36]----Batch Time 0.339 (0.455)----Data Time 0.053 (0.074)----Cont. Loss 0.0398 (0.0369)----Adv. Loss 2.6871 (3.0129)----Disc. Loss 0.2166 (0.3282)\n",
      "Epoch: [9][0/36]----Batch Time 0.478 (0.478)----Data Time 0.074 (0.074)----Cont. Loss 0.0390 (0.0390)----Adv. Loss 4.8857 (4.8857)----Disc. Loss 0.4744 (0.4744)\n",
      "Epoch: [9][1/36]----Batch Time 0.453 (0.465)----Data Time 0.073 (0.073)----Cont. Loss 0.0351 (0.0370)----Adv. Loss 5.8071 (5.3464)----Disc. Loss 0.4671 (0.4707)\n",
      "Epoch: [9][2/36]----Batch Time 0.459 (0.463)----Data Time 0.076 (0.074)----Cont. Loss 0.0411 (0.0384)----Adv. Loss 4.5948 (5.0959)----Disc. Loss 0.1153 (0.3523)\n",
      "Epoch: [9][3/36]----Batch Time 0.456 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0375 (0.0382)----Adv. Loss 2.8384 (4.5315)----Disc. Loss 0.1908 (0.3119)\n",
      "Epoch: [9][4/36]----Batch Time 0.458 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0387 (0.0383)----Adv. Loss 3.3701 (4.2992)----Disc. Loss 0.1473 (0.2790)\n",
      "Epoch: [9][5/36]----Batch Time 0.461 (0.461)----Data Time 0.075 (0.074)----Cont. Loss 0.0442 (0.0393)----Adv. Loss 3.7437 (4.2066)----Disc. Loss 0.1545 (0.2582)\n",
      "Epoch: [9][6/36]----Batch Time 0.460 (0.461)----Data Time 0.074 (0.074)----Cont. Loss 0.0353 (0.0387)----Adv. Loss 5.4574 (4.3853)----Disc. Loss 0.1144 (0.2377)\n",
      "Epoch: [9][7/36]----Batch Time 0.458 (0.460)----Data Time 0.075 (0.074)----Cont. Loss 0.0338 (0.0381)----Adv. Loss 7.1450 (4.7303)----Disc. Loss 0.1393 (0.2254)\n",
      "Epoch: [9][8/36]----Batch Time 0.457 (0.460)----Data Time 0.074 (0.074)----Cont. Loss 0.0338 (0.0376)----Adv. Loss 6.7234 (4.9517)----Disc. Loss 0.2187 (0.2247)\n",
      "Epoch: [9][9/36]----Batch Time 0.459 (0.460)----Data Time 0.076 (0.074)----Cont. Loss 0.0327 (0.0371)----Adv. Loss 6.4401 (5.1006)----Disc. Loss 0.0171 (0.2039)\n",
      "Epoch: [9][10/36]----Batch Time 0.460 (0.460)----Data Time 0.074 (0.074)----Cont. Loss 0.0384 (0.0372)----Adv. Loss 5.7843 (5.1627)----Disc. Loss 0.0286 (0.1880)\n",
      "Epoch: [9][11/36]----Batch Time 0.456 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0391 (0.0374)----Adv. Loss 4.8184 (5.1340)----Disc. Loss 0.1384 (0.1838)\n",
      "Epoch: [9][12/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0418 (0.0377)----Adv. Loss 4.3056 (5.0703)----Disc. Loss 0.1704 (0.1828)\n",
      "Epoch: [9][13/36]----Batch Time 0.460 (0.459)----Data Time 0.075 (0.074)----Cont. Loss 0.0325 (0.0374)----Adv. Loss 4.4548 (5.0263)----Disc. Loss 0.2258 (0.1859)\n",
      "Epoch: [9][14/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.074)----Cont. Loss 0.0420 (0.0377)----Adv. Loss 6.0610 (5.0953)----Disc. Loss 0.5166 (0.2079)\n",
      "Epoch: [9][15/36]----Batch Time 0.460 (0.459)----Data Time 0.078 (0.075)----Cont. Loss 0.0425 (0.0380)----Adv. Loss 5.4570 (5.1179)----Disc. Loss 0.3919 (0.2194)\n",
      "Epoch: [9][16/36]----Batch Time 0.460 (0.459)----Data Time 0.078 (0.075)----Cont. Loss 0.0338 (0.0377)----Adv. Loss 2.7958 (4.9813)----Disc. Loss 0.6668 (0.2457)\n",
      "Epoch: [9][17/36]----Batch Time 0.462 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0394 (0.0378)----Adv. Loss 2.9869 (4.8705)----Disc. Loss 0.7516 (0.2738)\n",
      "Epoch: [9][18/36]----Batch Time 0.459 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0390 (0.0379)----Adv. Loss 7.0670 (4.9861)----Disc. Loss 1.9345 (0.3612)\n",
      "Epoch: [9][19/36]----Batch Time 0.460 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0413 (0.0381)----Adv. Loss 0.8027 (4.7770)----Disc. Loss 1.5335 (0.4199)\n",
      "Epoch: [9][20/36]----Batch Time 0.459 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0381 (0.0381)----Adv. Loss 0.8915 (4.5919)----Disc. Loss 1.1148 (0.4529)\n",
      "Epoch: [9][21/36]----Batch Time 0.463 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0395 (0.0381)----Adv. Loss 3.0501 (4.5219)----Disc. Loss 0.3498 (0.4483)\n",
      "Epoch: [9][22/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0361 (0.0380)----Adv. Loss 4.0045 (4.4994)----Disc. Loss 0.9747 (0.4711)\n",
      "Epoch: [9][23/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0331 (0.0378)----Adv. Loss 3.4674 (4.4564)----Disc. Loss 0.3063 (0.4643)\n",
      "Epoch: [9][24/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0386 (0.0379)----Adv. Loss 2.7436 (4.3879)----Disc. Loss 0.2315 (0.4550)\n",
      "Epoch: [9][25/36]----Batch Time 0.459 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0409 (0.0380)----Adv. Loss 1.9259 (4.2932)----Disc. Loss 0.4694 (0.4555)\n",
      "Epoch: [9][26/36]----Batch Time 0.457 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0419 (0.0381)----Adv. Loss 2.9379 (4.2430)----Disc. Loss 0.2552 (0.4481)\n",
      "Epoch: [9][27/36]----Batch Time 0.457 (0.459)----Data Time 0.074 (0.075)----Cont. Loss 0.0393 (0.0382)----Adv. Loss 3.7226 (4.2244)----Disc. Loss 0.2979 (0.4427)\n",
      "Epoch: [9][28/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0396 (0.0382)----Adv. Loss 3.8082 (4.2100)----Disc. Loss 0.3764 (0.4405)\n",
      "Epoch: [9][29/36]----Batch Time 0.455 (0.459)----Data Time 0.073 (0.075)----Cont. Loss 0.0333 (0.0381)----Adv. Loss 3.1063 (4.1732)----Disc. Loss 0.2145 (0.4329)\n",
      "Epoch: [9][30/36]----Batch Time 0.462 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0374 (0.0380)----Adv. Loss 1.8845 (4.0994)----Disc. Loss 0.3964 (0.4317)\n",
      "Epoch: [9][31/36]----Batch Time 0.458 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0367 (0.0380)----Adv. Loss 3.2173 (4.0718)----Disc. Loss 0.2069 (0.4247)\n",
      "Epoch: [9][32/36]----Batch Time 0.459 (0.459)----Data Time 0.076 (0.075)----Cont. Loss 0.0453 (0.0382)----Adv. Loss 2.8649 (4.0353)----Disc. Loss 0.2608 (0.4198)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][33/36]----Batch Time 0.456 (0.459)----Data Time 0.075 (0.075)----Cont. Loss 0.0397 (0.0383)----Adv. Loss 3.2386 (4.0118)----Disc. Loss 0.2046 (0.4134)\n",
      "Epoch: [9][34/36]----Batch Time 0.461 (0.459)----Data Time 0.078 (0.075)----Cont. Loss 0.0366 (0.0382)----Adv. Loss 3.6153 (4.0005)----Disc. Loss 0.2465 (0.4087)\n",
      "Epoch: [9][35/36]----Batch Time 0.341 (0.456)----Data Time 0.055 (0.074)----Cont. Loss 0.0344 (0.0381)----Adv. Loss 2.6556 (3.9734)----Disc. Loss 0.2581 (0.4056)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "from models import Generator, Discriminator, TruncatedVGG19\n",
    "from datasets import SRDataset\n",
    "from utils import *\n",
    "import csv\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Data parameters\n",
    "data_folder = './'  # folder with JSON data files\n",
    "crop_size = 96  # crop size of target HR images\n",
    "scaling_factor = 2  # the scaling factor for the generator; the input LR images will be downsampled from the target HR images by this factor\n",
    "\n",
    "# Generator parameters\n",
    "large_kernel_size_g = 9  # kernel size of the first and last convolutions which transform the inputs and outputs\n",
    "small_kernel_size_g = 3  # kernel size of all convolutions in-between, i.e. those in the residual and subpixel convolutional blocks\n",
    "n_channels_g = 64  # number of channels in-between, i.e. the input and output channels for the residual and subpixel convolutional blocks\n",
    "n_blocks_g = 16  # number of residual blocks\n",
    "srresnet_checkpoint = './../E100Bt8_srresnet.pth.tar'  # filepath of the trained SRResNet checkpoint used for initialization\n",
    "\n",
    "# Discriminator parameters\n",
    "kernel_size_d = 3  # kernel size in all convolutional blocks\n",
    "n_channels_d = 64  # number of output channels in the first convolutional block, after which it is doubled in every 2nd block thereafter\n",
    "n_blocks_d = 8  # number of convolutional blocks\n",
    "fc_size_d = 1024  # size of the first fully connected layer\n",
    "\n",
    "# Learning parameters\n",
    "checkpoint = None  # path to model (SRGAN) checkpoint, None if none\n",
    "batch_size = 64  # batch size\n",
    "start_epoch = 0  # start at this epoch\n",
    "iterations = 2e5  # number of training iterations\n",
    "workers = 0  # number of workers for loading data in the DataLoader\n",
    "vgg19_i = 5  # the index i in the definition for VGG loss; see paper or models.py\n",
    "vgg19_j = 4  # the index j in the definition for VGG loss; see paper or models.py\n",
    "beta = 1e-3  # the coefficient to weight the adversarial loss in the perceptual loss\n",
    "print_freq = 1  # print training status once every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "grad_clip = None  # clip if gradients are exploding\n",
    "index = 0\n",
    "\n",
    "# Default device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, epoch, checkpoint, srresnet_checkpoint\n",
    "\n",
    "    # Initialize model or load checkpoint\n",
    "    if checkpoint is None:\n",
    "        # Generator\n",
    "        generator = Generator(large_kernel_size=large_kernel_size_g,\n",
    "                              small_kernel_size=small_kernel_size_g,\n",
    "                              n_channels=n_channels_g,\n",
    "                              n_blocks=n_blocks_g,\n",
    "                              scaling_factor=scaling_factor)\n",
    "\n",
    "        # Initialize generator network with pretrained SRResNet\n",
    "        generator.initialize_with_srresnet(srresnet_checkpoint=srresnet_checkpoint)\n",
    "\n",
    "        # Initialize generator's optimizer\n",
    "        optimizer_g = torch.optim.Adam(params=filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "                                       lr=lr)\n",
    "\n",
    "        # Discriminator\n",
    "        discriminator = Discriminator(kernel_size=kernel_size_d,\n",
    "                                      n_channels=n_channels_d,\n",
    "                                      n_blocks=n_blocks_d,\n",
    "                                      fc_size=fc_size_d)\n",
    "\n",
    "        # Initialize discriminator's optimizer\n",
    "        optimizer_d = torch.optim.Adam(params=filter(lambda p: p.requires_grad, discriminator.parameters()),\n",
    "                                       lr=lr)\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        generator = checkpoint['generator']\n",
    "        discriminator = checkpoint['discriminator']\n",
    "        optimizer_g = checkpoint['optimizer_g']\n",
    "        optimizer_d = checkpoint['optimizer_d']\n",
    "        print(\"\\nLoaded checkpoint from epoch %d.\\n\" % (checkpoint['epoch'] + 1))\n",
    "\n",
    "    # Truncated VGG19 network to be used in the loss calculation\n",
    "    truncated_vgg19 = TruncatedVGG19(i=vgg19_i, j=vgg19_j)\n",
    "    truncated_vgg19.eval()\n",
    "\n",
    "    # Loss functions\n",
    "    content_loss_criterion = nn.MSELoss()\n",
    "    adversarial_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Move to default device\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    truncated_vgg19 = truncated_vgg19.to(device)\n",
    "    content_loss_criterion = content_loss_criterion.to(device)\n",
    "    adversarial_loss_criterion = adversarial_loss_criterion.to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    train_dataset = SRDataset(data_folder,\n",
    "                              split='train',\n",
    "                              crop_size=crop_size,\n",
    "                              scaling_factor=scaling_factor,\n",
    "                              lr_img_type='imagenet-norm',\n",
    "                              hr_img_type='imagenet-norm')\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "    # Total number of epochs to train for\n",
    "    epochs = int(iterations // len(train_loader) + 1)\n",
    "    csvfile = open('./../img/loss_ep20_bt8.csv','w')\n",
    "    filewriter = csv.writer(csvfile, delimiter = ',', quotechar = '|',quoting = csv.QUOTE_MINIMAL)\n",
    "    filewriter.writerow(['Nomor','Epoch', 'Cont. Loss','Adv. Loss','Disc. Loss' ])\n",
    "    \n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, 10):\n",
    "\n",
    "        # At the halfway point, reduce learning rate to a tenth\n",
    "        if epoch == int((iterations / 2) // len(train_loader) + 1):\n",
    "            adjust_learning_rate(optimizer_g, 0.1)\n",
    "            adjust_learning_rate(optimizer_d, 0.1)\n",
    "\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              generator=generator,\n",
    "              discriminator=discriminator,\n",
    "              truncated_vgg19=truncated_vgg19,\n",
    "              content_loss_criterion=content_loss_criterion,\n",
    "              adversarial_loss_criterion=adversarial_loss_criterion,\n",
    "              optimizer_g=optimizer_g,\n",
    "              optimizer_d=optimizer_d,\n",
    "              epoch=epoch,\n",
    "              idx = index,\n",
    "              filewriter = filewriter)\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'generator': generator,\n",
    "                    'discriminator': discriminator,\n",
    "                    'optimizer_g': optimizer_g,\n",
    "                    'optimizer_d': optimizer_d},\n",
    "                   'E500Bt64_srgan.pth.tar')\n",
    "\n",
    "\n",
    "def train(train_loader, generator, discriminator, truncated_vgg19, content_loss_criterion, adversarial_loss_criterion,\n",
    "          optimizer_g, optimizer_d, epoch, idx, filewriter):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: train dataloader\n",
    "    :param generator: generator\n",
    "    :param discriminator: discriminator\n",
    "    :param truncated_vgg19: truncated VGG19 network\n",
    "    :param content_loss_criterion: content loss function (Mean Squared-Error loss)\n",
    "    :param adversarial_loss_criterion: adversarial loss function (Binary Cross-Entropy loss)\n",
    "    :param optimizer_g: optimizer for the generator\n",
    "    :param optimizer_d: optimizer for the discriminator\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    # Set to train mode\n",
    "    generator.train()\n",
    "    discriminator.train()  # training mode enables batch normalization\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses_c = AverageMeter()  # content loss\n",
    "    losses_a = AverageMeter()  # adversarial loss in the generator\n",
    "    losses_d = AverageMeter()  # adversarial loss in the discriminator\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (lr_imgs, hr_imgs) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        lr_imgs = lr_imgs.to(device)  # (batch_size (N), 3, 24, 24), imagenet-normed\n",
    "        hr_imgs = hr_imgs.to(device)  # (batch_size (N), 3, 96, 96), imagenet-normed\n",
    "\n",
    "        # GENERATOR UPDATE\n",
    "\n",
    "        # Generate\n",
    "        sr_imgs = generator(lr_imgs)  # (N, 3, 96, 96), in [-1, 1]\n",
    "        sr_imgs = convert_image(sr_imgs, source='[-1, 1]', target='imagenet-norm')  # (N, 3, 96, 96), imagenet-normed\n",
    "\n",
    "        # Calculate VGG feature maps for the super-resolved (SR) and high resolution (HR) images\n",
    "        sr_imgs_in_vgg_space = truncated_vgg19(sr_imgs)\n",
    "        hr_imgs_in_vgg_space = truncated_vgg19(hr_imgs).detach()  # detached because they're constant, targets\n",
    "\n",
    "        # Discriminate super-resolved (SR) images\n",
    "        sr_discriminated = discriminator(sr_imgs)  # (N)\n",
    "\n",
    "        # Calculate the Perceptual loss\n",
    "        content_loss = content_loss_criterion(sr_imgs_in_vgg_space, hr_imgs_in_vgg_space)\n",
    "        adversarial_loss = adversarial_loss_criterion(sr_discriminated, torch.ones_like(sr_discriminated))\n",
    "        perceptual_loss = content_loss + beta * adversarial_loss\n",
    "\n",
    "        # Back-prop.\n",
    "        optimizer_g.zero_grad()\n",
    "        perceptual_loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer_g, grad_clip)\n",
    "\n",
    "        # Update generator\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Keep track of loss\n",
    "        losses_c.update(content_loss.item(), lr_imgs.size(0))\n",
    "        losses_a.update(adversarial_loss.item(), lr_imgs.size(0))\n",
    "\n",
    "        # DISCRIMINATOR UPDATE\n",
    "\n",
    "        # Discriminate super-resolution (SR) and high-resolution (HR) images\n",
    "        hr_discriminated = discriminator(hr_imgs)\n",
    "        sr_discriminated = discriminator(sr_imgs.detach())\n",
    "        # But didn't we already discriminate the SR images earlier, before updating the generator (G)? Why not just use that here?\n",
    "        # Because, if we used that, we'd be back-propagating (finding gradients) over the G too when backward() is called\n",
    "        # It's actually faster to detach the SR images from the G and forward-prop again, than to back-prop. over the G unnecessarily\n",
    "        # See FAQ section in the tutorial\n",
    "\n",
    "        # Binary Cross-Entropy loss\n",
    "        adversarial_loss = adversarial_loss_criterion(sr_discriminated, torch.zeros_like(sr_discriminated)) + \\\n",
    "                           adversarial_loss_criterion(hr_discriminated, torch.ones_like(hr_discriminated))\n",
    "\n",
    "        # Back-prop.\n",
    "        optimizer_d.zero_grad()\n",
    "        adversarial_loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer_d, grad_clip)\n",
    "\n",
    "        # Update discriminator\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Keep track of loss\n",
    "        losses_d.update(adversarial_loss.item(), hr_imgs.size(0))\n",
    "\n",
    "        # Keep track of batch times\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        # Reset start time\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]----'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})----'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})----'\n",
    "                  'Cont. Loss {loss_c.val:.4f} ({loss_c.avg:.4f})----'\n",
    "                  'Adv. Loss {loss_a.val:.4f} ({loss_a.avg:.4f})----'\n",
    "                  'Disc. Loss {loss_d.val:.4f} ({loss_d.avg:.4f})'.format(epoch,\n",
    "                                                                          i,\n",
    "                                                                          len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time,\n",
    "                                                                          loss_c=losses_c,\n",
    "                                                                          loss_a=losses_a,\n",
    "                                                                          loss_d=losses_d))\n",
    "            idx = idx + 1\n",
    "            filewriter.writerow([idx,epoch,\n",
    "                                 '{loss_c.val:.4f}'.format(loss_c = losses_c),\n",
    "                                 '{loss_a.val:.4f}'.format(loss_a = losses_a),\n",
    "                                 '{loss_d.val:.4f}'.format(loss_d = losses_d)])\n",
    "            \n",
    "    del lr_imgs, hr_imgs, sr_imgs, hr_imgs_in_vgg_space, sr_imgs_in_vgg_space, hr_discriminated, sr_discriminated  # free some memory since their histories may be stored\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
